---
title: "621-hw3"
author: "Document Author"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
## libraries
```{r warning=FALSE, message=FALSE}
library(reshape2)
library(ggplot2)
library(dplyr)
library(psych)
library(MASS)
library(car)
library(Hmisc)
```

## explore data
```{r}
# load dataset
data <- read.csv('crime-training-data_modified.csv')
head(data)
```
13 variables in total
```{r}
# number of variables in total
names(data) %>% length()
```
from summary, there are no missing values reported but some predictors are skewed.
```{r}
# brief summary
summary(data)
```


```{r}
# make box plot for all variables
data.m <- melt(data, id.vars = 'target')
head(data.m)
ggplot(data.m, aes(x = variable, y = value)) + geom_boxplot() + facet_wrap(~ variable, scales = 'free')
```
```{r}
# histogram of all columns
par(mar = c(1,1,1,1))
hist.data.frame(data)
```

from correlation plot, it seems suburb border to charles river will have less impact on predicting target for some predictors
```{r warning=FALSE, message=FALSE}
# correlation between predictors and response
par(mar = c(1,1,1,1))
data %>% corPlot(main = 'whole data set')
```

the correlation between predictors doesn't appear to be linear
```{r}
# correlation between predictors
pairs(data)
```

## building model

### linear regression(not valid)

from the summary, the model only explains 61% of data, and there are more than one predictors don't have significant impact in predicting data, the added variable plot also showing the same.

from residual plot, the variance of residual is not constant. QQ plot shows non-normality happen in the data. variance of error is not elliptically symmetric, it also shows some pattern

As a result, this is a not a valid model for data
```{r}
data.lm <- lm(target ~ ., data = data)
summary(data.lm)
plot(data.lm)
```

### logistic regression

#### first model(general)
from added variable plot, we see that there are some variables are not helping much in predicting response variable, therefore, I am going to reduce these variables.

```{r}
logit1 <- glm(target ~ . , data = data, family = binomial)
summary(logit1)
```
added variable plot prove that variables 'nox', 'age', 'dis', 'rad', 'tax', 'ptratio' and 'medv' have statistically significance in predicting response variable. Since these variable are either skewed or have outliers or both. I am going to transform these variable individually.
```{r}
# added variable plot
avPlots(logit1)
```

### data transfromation

```{r warning=FALSE, message=FALSE}
attach(data)

# transform nox
nox.bc <- boxcox(lm(nox ~ 1, data))
nox.pow <- nox.bc$x[which.max(nox.bc$y)]
nox.t <- back_transform(nox, nox.pow)

# transform age
age.bc <- boxcox(lm(age ~ 1, data))
age.pow <- age.bc$x[which.max(age.bc$y)]
age.t <- back_transform(age, age.pow)

# transform dis
dis.bc <- boxcox(lm(dis ~ 1, data))
dis.pow <- dis.bc$x[which.max(dis.bc$y)]
dis.t <- back_transform(dis, dis.pow)

# transform rad
rad.bc <- boxcox(lm(rad ~ 1, data))
rad.pow <- rad.bc$x[which.max(rad.bc$y)]
rad.t <- back_transform(rad, rad.pow)

# transform tax
tax.bc <- boxcox(lm(tax ~ 1, data))
tax.pow <- tax.bc$x[which.max(tax.bc$y)]
tax.t <- back_transform(tax, tax.pow)

# transform ptratio
ptratio.bc <- boxcox(lm(ptratio ~ 1, data))
ptratio.pow <- ptratio.bc$x[which.max(ptratio.bc$y)]
ptratio.t <- back_transform(ptratio, ptratio.pow)

# transform medv
medv.bc <- boxcox(lm(medv ~ 1, data))
medv.pow <- medv.bc$x[which.max(medv.bc$y)]
medv.t <- back_transform(medv, medv.pow)

subset <- data.frame(target, nox.t, age.t, dis.t, rad.t, tax.t, ptratio.t, medv.t)
```

### second model(reduced version)
```{r}
logit2 <- glm(target ~ ., data = subset, family = binomial)
summary(logit2)
```

